#! /usr/bin/env -S /opt/dcp/bin/dcp-evaluator --webgpu -f lib/console.js -f lib/rt.js -f lib/timers.js
/**
 * @file        webgpu-matmul.v8e.js - Simple webGPU matmul operation to run on
 *                                     bare-metal dcp-evaluator
 * @author      Ryan Saweczko, Amir Sojoodi
 * @date        Aug 2024
 *
 * 
 * Adapted from Amir's matmul benchmark to work on the bare-metal dcp-evaluator
 */

globalThis.main = async function main()
{
  // dcp-native > 7.2.0 lazy loads webgpu
  if (typeof initWebGPU === 'function')
    await initWebGPU();  

  const BLOCK_SIZE_X = 16;
  const BLOCK_SIZE_Y = 16;

  let device = null;
  let adapter = null;
  let matrixWidth;

  let firstMatrix;
  let secondMatrix;

  let gpuBufferFirstMatrix;
  let gpuBufferSecondMatrix;

  let arrayBufferFirstMatrix;
  let arrayBufferSecondMatrix;
  let resultMatrixBufferSize;
  let resultMatrixBuffer;
  let gpuReadBuffer;

  async function initializeWebGPU()
  {
    if (!navigator.gpu)
      throw new Error('This evaluator does not support WebGPU');

    adapter = await navigator.gpu.requestAdapter();
    if (!adapter)
    {
      console.log('Failed to get GPU adapter.');
      return;
    }

    device = await adapter.requestDevice({ requiredFeatures: [] });
    return true;
  }

  async function getAdapterInfo()
  {
    const adapterInfo = await (adapter.requestAdapterInfo ? adapter.requestAdapterInfo() : undefined);
    if (adapterInfo === undefined)
      return 'Warning: cannot get adapterInfo';

    const packedAdapterInfo =
        `IsCompatibilityMode: ${adapter.isCompatibilityMode}\n` +
        `Vendor: ${adapterInfo.vendor}\n` +
        `Architecture: ${adapterInfo.vendor}\n` +
        `Backend: ${adapterInfo.backend}\n` +
        `Description: ${adapterInfo.description}\n` +
        `Type: ${adapterInfo.type}`;

    return packedAdapterInfo;
  }

  async function initDeviceData(matrix_width)
  {
    // Matrices are like as follows:
    // [rows, columns, (values)]);
    matrixWidth = matrix_width;

    // First Matrix
    firstMatrix = new Float32Array((matrixWidth * matrixWidth) + 2);
    firstMatrix[0] = matrixWidth;
    firstMatrix[1] = matrixWidth;

    for (let i = 2; i < matrixWidth * matrixWidth + 2; i++)
      firstMatrix[i] = 1;

    gpuBufferFirstMatrix = device.createBuffer({
      mappedAtCreation: true,
      size: firstMatrix.byteLength,
      usage: GPUBufferUsage.STORAGE
    });
    arrayBufferFirstMatrix = gpuBufferFirstMatrix.getMappedRange();

    new Float32Array(arrayBufferFirstMatrix).set(firstMatrix);
    gpuBufferFirstMatrix.unmap();

    secondMatrix = new Float32Array((matrixWidth * matrixWidth) + 2);
    secondMatrix[0] = matrixWidth;
    secondMatrix[1] = matrixWidth;

    for (let i = 2; i < matrixWidth * matrixWidth + 2; i++)
      secondMatrix[i] = 1;

    gpuBufferSecondMatrix = device.createBuffer({
      mappedAtCreation: true,
      size: secondMatrix.byteLength,
      usage: GPUBufferUsage.STORAGE
    });
    arrayBufferSecondMatrix = gpuBufferSecondMatrix.getMappedRange();
    new Float32Array(arrayBufferSecondMatrix).set(secondMatrix);
    gpuBufferSecondMatrix.unmap();


    // Result Matrix
    resultMatrixBufferSize = Float32Array.BYTES_PER_ELEMENT * (2 + firstMatrix[0] * secondMatrix[1]);
    resultMatrixBuffer = device.createBuffer({
      size: resultMatrixBufferSize,
      usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC
    });

    // Get a GPU buffer for reading in an unmapped state.
    gpuReadBuffer = device.createBuffer({
      size: resultMatrixBufferSize,
      usage: GPUBufferUsage.COPY_DST | GPUBufferUsage.MAP_READ
    });
  }

  async function benchmark() {
    // Compute shader code
    const shaderModule = device.createShaderModule({
      code: `
        const BLOCK_SIZE_X = 16;
        const BLOCK_SIZE_Y = 16;

        struct Matrix {
          size : vec2<f32>,
          numbers: array<f32>,
        }
  
        @group(0) @binding(0) var<storage, read> firstMatrix : Matrix;
        @group(0) @binding(1) var<storage, read> secondMatrix : Matrix;
        @group(0) @binding(2) var<storage, read_write> resultMatrix : Matrix;
  
        @compute @workgroup_size(BLOCK_SIZE_X, BLOCK_SIZE_Y)
        fn main(@builtin(global_invocation_id) global_id : vec3<u32>) {
          // Guard against out-of-bounds work group sizes
          if (global_id.x >= u32(firstMatrix.size.x) || global_id.y >= u32(secondMatrix.size.y)) {
            return;
          }
  
          resultMatrix.size = vec2(firstMatrix.size.x, secondMatrix.size.y);
  
          let resultCell = vec2(global_id.x, global_id.y);
          var result = 0.0;
          for (var i = 0u; i < u32(firstMatrix.size.y); i = i + 1u) {
            let a = i + resultCell.x * u32(firstMatrix.size.y);
            let b = resultCell.y + i * u32(secondMatrix.size.y);
            result = result + firstMatrix.numbers[a] * secondMatrix.numbers[b];
          }
  
          let index = resultCell.y + resultCell.x * u32(secondMatrix.size.y);
          resultMatrix.numbers[index] = result;
        }
      `
    });

    // Pipeline setup
    const computePipeline = device.createComputePipeline(
        {layout: 'auto', compute: {module: shaderModule, entryPoint: 'main'}});

    // Bind group
    const bindGroup = device.createBindGroup({
      layout: computePipeline.getBindGroupLayout(0 /* index */),
      entries: [
        {binding: 0, resource: {buffer: gpuBufferFirstMatrix}},
        {binding: 1, resource: {buffer: gpuBufferSecondMatrix}},
        {binding: 2, resource: {buffer: resultMatrixBuffer}}
      ]
    });

    // Commands submission
    const commandEncoder = device.createCommandEncoder();

    const passEncoder = commandEncoder.beginComputePass();
    passEncoder.setPipeline(computePipeline);
    passEncoder.setBindGroup(0, bindGroup);
    const workgroupCountX = Math.ceil(firstMatrix[0] / BLOCK_SIZE_X);
    const workgroupCountY = Math.ceil(secondMatrix[1] / BLOCK_SIZE_Y);
    passEncoder.dispatchWorkgroups(workgroupCountX, workgroupCountY);
    passEncoder.end();

    // Encode commands for copying buffer to buffer.
    commandEncoder.copyBufferToBuffer(
        resultMatrixBuffer /* source buffer */, 0 /* source offset */,
        gpuReadBuffer /* destination buffer */, 0 /* destination offset */,
        resultMatrixBufferSize /* size */
    );

    // Submit GPU commands.
    const gpuCommands = commandEncoder.finish();
    device.queue.submit([gpuCommands]);

    // await device.queue.onSubmittedWorkDone();
    // Read results
    await gpuReadBuffer.mapAsync(GPUMapMode.READ);

    const arrayBuffer = gpuReadBuffer.getMappedRange();
    const resultBuffer = new Float32Array(arrayBuffer);
    // To verify gpu calculations were correct, may log resultBuffer
  }

  async function cleanup() {
    // Freeing buffers
    gpuReadBuffer.unmap();

    gpuBufferFirstMatrix.destroy();
    gpuBufferSecondMatrix.destroy();
    resultMatrixBuffer.destroy();

    device.destroy();
  }

  const MATRIX_WIDTH = 100;

  await initializeWebGPU();
  await initDeviceData(MATRIX_WIDTH);

  console.log(await getAdapterInfo());
  console.log('running matmul on GPU...');
  await benchmark();
  console.log('benchmark run, cleaning up');
  cleanup();
  console.log('done');
}
